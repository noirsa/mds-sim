---
title: "Lab Assignment 1"
author: "Zheshuo and Geming"
date: "2025-10-05"
output: html_document
---

# ASSIGNMENT 1: GEORGIA HOUSE PRICE

## 0. Before Starting

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Clear the plots
rm(list=ls()) # Clear the environment
set.seed(123) # Set a seed to reproduce outcomes
```

We start by loading essential libraries, importing the data, and defining functions to simplify repetitive operations.

```{r}
# Installing dependencies
install.packages("lubridate")
```

```{r include = FALSE}
# Loading libraries
library(moments)
library(car)
library(chemometrics)
library(mice)
library(missMDA)
library(FactoMineR)
library(corrplot)
library(VIM)
library(dplyr)
library(ggplot2)
library(AER)
library(MASS)
library(dplyr)
library(lubridate)
library(stringr)
library(readr)
library(tidyr)
library(tidyselect)
```

```{r}
# Importing the main data of the assignment
georgia <- read.csv("RealEstate_Georgia.csv")
```

The dataset contains 6168 housing ads from different cities in different counties of the Georgia state, there are posts from 2014 to 2021 but majority of data are for 2021. For a fair analysis, the houses that are posted in 2021 are taken into account.

```{r}
# Get the dimension of the dataset
dim(georgia) # 6168 obs + 39 variables
```

```{r}
# Show the name of columns
names(georgia)
```

```{r}
# Check the structure of the dataset
str(georgia)
```

```{r}
# Use summary function to get a fast understanding of the dataset
summary(georgia)
```

```{r}
# Extract years from the column datePostedString
georgia$datePostedString <- as.Date(georgia$datePostedString, format = "%Y-%m-%d")
georgia$datePostedString <- as.numeric(format(georgia$datePostedString, "%Y"))
```

## 1. Explanatory Data Analysis

In this section, we perform a crucial step in any data science project, especially when preparing data for modeling. A comprehensive descriptive analysis is carried out for each variable, emphasizing their most relevant characteristics. We proceed with a column-by-column examination of the dataset, followed by the generation of a data quality report. Subsequently, we prepare the data for the modeling phase by handling missing values through imputation techniques, removing non-informative variables, and creating new derived features where appropriate.

```{r}
# The function we need for EDA processes
# Use given Q1 & Q3 to compute indexes of outliers
calculate_outliers <- function(x) {
  # Check for regular outliers
  col_name <- deparse(substitute(x))
  Boxplot(x, main = "Boxplot", ylab = col_name)
  outliers <- boxplot.stats(x)$out

  # Compute quartiles and IQR
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1

  # Define thresholds
  lower_mild <- Q1 - 1.5 * IQR
  upper_mild <- Q3 + 1.5 * IQR
  lower_extreme <- Q1 - 3 * IQR
  upper_extreme <- Q3 + 3 * IQR

  # Identify mild and extreme outliers
  mild_idx <- which((x < lower_mild | x > upper_mild))
  extreme_idx <- which((x < lower_extreme | x > upper_extreme))
  
  # Count
  num_mild <- length(mild_idx)
  num_extreme <- length(extreme_idx)

  abline(h = c(lower_mild, upper_mild), col = "blue", lwd = 2)
  abline(h = c(lower_extreme, upper_extreme), col = "red", lwd = 2)

  # Return the results as a list
  return(list(
    num_mild = num_mild,
    num_extreme = num_extreme,
    mild_indexes = mild_idx,
    extreme_indexes = extreme_idx
  ))
}
```

**Variable 1: X.1**

Variable X.1 is a numerical variable with no missing values.
A quick inspection reveals that it serves as a unique identifier for each observation, since the number of unique values equals the total number of rows.
Therefore, this variable does not contain meaningful numerical information for statistical analysis. Normality and outlier tests were not performed, as the variable is an ID rather than a continuous numeric feature. It contains no missing values thus imputation is not needed. This variable does not contain any outliers. Interestingly, the maximum value (6468) in the data does not match the number of columns (6168), maybe these ids belong to the observations of the original dataset where rental houses from other states are also stored.

```{r}
# Summary of the column
summary(georgia$X.1)
# Any missing values
sum(is.na(georgia$X.1))
# First five elements
georgia$X.1[1:5]
# Number of unique values
unique_counts<-length(unique(georgia$X.1))
# Verify if all values are unique
unique_counts == nrow(georgia)
```

**Variable 2: X**

X is a numerical variable without missing values. It is very similar to the previous variable in all aspects. Although the range of its values is twice of the previous one ([1,6428] vs [25,13803]).

```{r}
# Summary of the column
summary(georgia$X)
# Any missing values
sum(is.na(georgia$X))
# First five elements
georgia$X[1:5]
# Number of unique values
unique_counts<-length(unique(georgia$X))
# Verify if all values are unique
unique_counts == nrow(georgia)

```

**Variable 3: id**

This categorical variable is suppose to contain the unique identifier of each row.
This variable does not have missing values. However, the number of unique values (5515 levels) do not match with the number of rows (6168 rows), so we can't really use it as an identifier in that regard. Nonetheless, there is another possibility that the dataset contains duplicated rows. And it happens that our idea has hit the bull's eye, it is true that the rows with the same ids are duplicated, most of their variables are the same with exception of the columns X.1, X and countyId. However, we also find out that not all rows with the same id are equal in terms of other variables, there are some which are likely to have errors in variables like garageSpaces, hasGarage and so on. But only 25 ids out of 653 duplicated ids show that pattern. Moreover, in the examples we present below, all sensible observations seem to be the last one, so in the later data cleaning section, we will keep only those observations.

```{r}
# Summary of the column
summary(georgia$id)
# Any missing values
sum(is.na(georgia$id))
# First five elements
georgia$id[1:5]
# Number of unique values
length(unique(georgia$id))

# Get duplicated ids
non_unique_ids <- georgia$id[duplicated(georgia$id)]
length(non_unique_ids)

# Observations with the same id are equal in most of the variables
which(georgia$id == non_unique_ids[1])

# obs 19 vs obs 5718
georgia[c(2975, 4502),]

# Let's try another pair
which(georgia$id == non_unique_ids[2])

# obs 19 vs obs 5718
georgia[c(1212, 4505),]

# Ignore the columsn X.1, X and countyId
ignore_cols <- c("X.1", "X", "countyId")
compare_cols <- setdiff(names(georgia), c(ignore_cols))

# For each duplicated id, check if all its rows are identical
same_rows <- sapply(non_unique_ids, function(idv) {
  sub <- georgia[georgia$id == idv, compare_cols, drop = FALSE]
  # All rows identical if only 1 unique row remains after removing duplicates
  nrow(unique(sub)) == 1
})

# Are all duplicates identical?
all(same_rows) # No

# Show two duplicates with different values in those variables
singular_ids <- names(same_rows)[which(same_rows == FALSE)]
georgia[which(georgia$id == singular_ids[1]),]
georgia[which(georgia$id == singular_ids[2]),]

# Number of singular ids
length(singular_ids)
```

**Variable 4: stateId**

This numerical variable contains the id of the state of the rental house in USA. However, since we only have observations from Georgia state, all these ids are the same (Georgia state's id is 16 for all rows). And it has no missing values.

```{r}
# Summary of the column
summary(georgia$stateId)
# Any missing values
sum(is.na(georgia$stateId))
# First five elements
georgia$stateId[1:5]
# Number of unique values
length(unique(georgia$stateId))

# Check frequency
table(georgia$stateId)

```

**Variable 5: countyId**

This numerical variable contains the id of counties in Georgia state. It has no missing values, and the number of unique values is slightly lower than the number of rows, which suggest some of the counties are used more than once. The data is not normally distributed and there is no presence of outliers.

```{r}
# Summary of the column
summary(georgia$countyId)
# Any missing values
sum(is.na(georgia$countyId))
# First five elements
georgia$countyId[1:5]

# Number of unique values
length(unique(georgia$countyId))

hist(georgia$countyId, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$countyId), sd(georgia$countyId)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
sci <- sample(georgia$countyId, 5000)
shapiro.test(sci)

# Boxplot to detect outliers
calculate_outliers(georgia$countyId)
```

**Variable 6: cityId**

This numerical variable represents the unique identifiers for cities in the state of Georgia. The cityId values range from 0 to 397,383, with 374 unique values. Notably, there are 340 occurrences of the value 0, which might indicate missing data.

```{r}
# Summary of the column
out_ci <- summary(georgia$cityId)
out_ci
# Any missing values
sum(is.na(georgia$cityId))
# First five elements
georgia$cityId[1:5]
# Number of unique values
length(unique(georgia$cityId))

# Check frequency
table(georgia$cityId)

```

**Variable 7: country**

This categorical variable contains the name of the country where the rental houses are found. Each house is geographically located in Georgia, a state in the USA, so its the same value for all the rows. This variable has no missing values.

```{r}
# Summary of the column
summary(georgia$country)
# Any missing values
sum(is.na(georgia$country))
# First five elements
georgia$country[1:5]
# Number of unique values
length(unique(georgia$country))
# Check frequency
table(georgia$country)

```

**Variable 8: datePostedString**

This variable was previously a categorical variable which contains the date when the rental house was published. We performed a conversion at the beginning to keep only the year. This variable has no missing values and most of the houses were posted on 2021, only a small number of them are posted 2020 (47).

```{r}
# Summary of the column
summary(georgia$datePostedString)
# Any missing values
sum(is.na(georgia$datePostedString))
# First five elements
georgia$datePostedString[1:5]
# Number of unique values
length(unique(georgia$datePostedString))

length(which(georgia$datePostedString != 2021))

plot(factor(georgia$datePostedString))
```

**Variable 9: is_bankOwned**

The variable is_bankOwned is a boolean variable that indicates whether the house is offered by a bank. This variable has no missing values and almost no house is owned by a bank, with exception of the observation 158.

```{r}
# Summary of the column
summary(georgia$is_bankOwned)
# Any missing values
sum(is.na(georgia$is_bankOwned))
# First five elements
georgia$is_bankOwned[1:5]
# Number of unique values
length(unique(georgia$is_bankOwned))

length(which(georgia$is_bankOwned != 0))
# Houses owned by a bank
which(georgia$is_bankOwned != 0)

plot(factor(georgia$is_bankOwned))
```

**Variable 10: is_forAuction**

The variable is_forAuction is almost identical to the previous column in terms of labels. It is also a boolean variable that indicates whether the house belongs to an auction. This variable has no missing values and no house is auctioned, with exception of the observation 3946.

```{r}
# Summary of the column
summary(georgia$is_forAuction)
# Any missing values
sum(is.na(georgia$is_forAuction))
# First five elements
georgia$is_forAuction[1:5]
# Number of unique values
length(unique(georgia$is_forAuction))

length(which(georgia$is_forAuction != 0))
# Houses belong to an auction
which(georgia$is_forAuction != 0)

plot(factor(georgia$is_forAuction))
```

**Variable 11: event**

The variable event is a categorical variable with 5 levels that indicates the sales type of each rental house. This variable has no missing values, around 5000 observations have "Listed for sale" and around 1000 have "Price change" in this variable. The rest of the labels have very low presence in the data.

```{r}

# Any missing values
sum(is.na(georgia$event))
# First five elements
georgia$event[1:5]
# Number of unique values
length(unique(georgia$event))

# Convert 'event' to factor for better handling as categorical variable
georgia$event <- factor(georgia$event)
# Summary of the column
summary(georgia$event)
plot(factor(georgia$event))
```

**Variable 12: time**

The time variable is a numerical variable representing the timestamp when each observation was collected. This variable has no missing values and contains 216 unique timestamps. The data was collected after 2021.

```{r}
# Summary of the column
out_ct <- summary(georgia$time)
out_ct
# Any missing values
sum(is.na(georgia$time))
# First five elements
georgia$time[1:5]
# Number of unique values
length(unique(georgia$time))

hist(georgia$time, breaks = 20, freq = F)
# Check for any duplicate timestamps (indicating possible data duplication)
sum(duplicated(georgia$time))  # Count how many duplicate timestamps exist

# convert time stamp to date
dates <- as.POSIXct(georgia$time / 1000, origin = "1970-01-01", tz = "UTC")
dates

```

**Variable 13: price**

The variable price is a numerical variable indicating the price of the rental houses. It ranges from 6,250 USD to 1,300,000 USD. This variable has no missing values and there are 1227 unique values. It's distribution resembles that of a normal distribution, but the Shapiro test says the otherwise. Moreover, there are 43 extreme outliers in the data.

```{r}
# Summary of the column
out_cp <- summary(georgia$price)
out_cp
# Any missing values
sum(is.na(georgia$price))
# First five elements
georgia$price[1:5]
# Number of unique values
length(unique(georgia$price))

hist(georgia$price, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$price), sd(georgia$price)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
sp <- sample(georgia$price, 5000)
shapiro.test(sp)

# Detect outlier
out <- calculate_outliers(georgia$price)

# Print number of extreme outliers
out$num_extreme

```

**Variable 14: pricePerSquareFoot**

The variable pricePerSquareFoot is a numerical variable that, as its name indicates, it stores the price per square foot of the rental houses. It ranges from 4.0 sqft to 205.00 sqft. This variable has no missing values and there are 440 unique values. It's not normally distributed and there are some considerably high values that might be errors while collecting the data. Those values are most likely extreme outliers in the data, which are 56.

```{r}
# Summary of the column
out_cppsf <- summary(georgia$pricePerSquareFoot)
out_cppsf
# Any missing values
sum(is.na(georgia$pricePerSquareFoot))
# First five elements
georgia$pricePerSquareFoot[1:5]
# Number of unique values
length(unique(georgia$pricePerSquareFoot))

hist(georgia$pricePerSquareFoot, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$pricePerSquareFoot), sd(georgia$pricePerSquareFoot)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
sppsf <- sample(georgia$pricePerSquareFoot, 5000)
shapiro.test(sppsf)

# Detect outlier
out <- calculate_outliers(georgia$pricePerSquareFoot)

# Print number of extreme outliers
out$num_extreme
```

**Variable 15: city**

The variable city is a categorical variable indicating the name of the city where the houses are located in. There are no missing data in the data and it has 383 unique values in this column. The most frequent city that appears in this data is Atlanta, followed by Marietta, Augusta, Columbus and Macon.

```{r}
# Summary of the column
summary(georgia$city)
# Any missing values
sum(is.na(georgia$city))
# First five elements
georgia$city[1:5]
# Number of unique values
length(unique(georgia$city))

plot(factor(georgia$city))
sort(table(georgia$city), decreasing = TRUE)[1:5]
```

**Variable 16: state**

This categorical variable contains the name of the state where the rental houses are found. Each house is geographically located in Georgia, so in this field we only have one value, which is Georgia, represented by GA. This variable has no missing values.

```{r}
# Summary of the column
summary(georgia$state)
# Any missing values
sum(is.na(georgia$state))
# First five elements
georgia$state[1:5]
# Number of unique values
length(unique(georgia$state))
```

**Variable 17: yearBuilt**

The variable yearBuilt is a numerical variable indicating the year when the house was built. There are 159 unique values. It's proved by the Shapiro test that it is not normally distributed and there are 16 extreme outliers. Those outliers are irreal, the maximum value of the data is 9999 which might indicate the presence of missing data in the dataset.

```{r}
# Summary of the column
out_cyb <- summary(georgia$yearBuilt)
out_cyb
# Any missing values
sum(is.na(georgia$yearBuilt))
# First five elements
georgia$yearBuilt[1:5]
# Number of unique values
length(unique(georgia$yearBuilt))

hist(georgia$yearBuilt, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$yearBuilt), sd(georgia$yearBuilt)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
syb <- sample(georgia$yearBuilt, 5000)
shapiro.test(syb)

# Detect outlier
out <- calculate_outliers(georgia$yearBuilt)

# Print number of extreme outliers
out$num_extreme
```

**Variable 18: streetAddress**

This categorical variable contains the street address of the rental houses. There are no missing values and there are 5514 levels, meaning some houses are geographically located in the same street.

```{r}
# Summary of the column
summary(georgia$streetAddress)
# Any missing values
sum(is.na(georgia$streetAddress))
# First five elements
georgia$streetAddress[1:5]
# Number of unique values
length(unique(georgia$streetAddress))
```

**Variable 19: zipcode**

Zipcode is a numerical variable containing the zipcode of each rental house. There are no missing values and there are 446 unique numerical values. The data is not normally distributed (confirmed by the Shapiro test). In this case we do not have any extreme outliers, but we do have 331 mild outliers.

```{r}
# Summary of the column
out_czc <- summary(georgia$zipcode)
out_czc
# Any missing values
sum(is.na(georgia$zipcode))
# First five elements
georgia$zipcode[1:5]
# Number of unique values
length(unique(georgia$zipcode))

hist(georgia$zipcode, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$zipcode), sd(georgia$zipcode)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
szc <- sample(georgia$zipcode, 5000)
shapiro.test(szc)

# Detect outlier
out <- calculate_outliers(georgia$zipcode)

# Print number of extreme outliers
out$num_mild
```

**Variable 20: longitude**

The numerical variable longitude contains the longitude of each of the rental houses. There are no missing values and there are 5437 unique numerical values. The data is not normally distributed (confirmed by the Shapiro test) and ranges from -85.57 to -80.97. In addition, there are 97 extreme outliers.

```{r}
# Summary of the column
out_clg <- summary(georgia$longitude)
out_clg
# Any missing values
sum(is.na(georgia$longitude))
# First five elements
georgia$longitude[1:5]
# Number of unique values
length(unique(georgia$longitude))

hist(georgia$longitude, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$longitude), sd(georgia$longitude)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
slg <- sample(georgia$longitude, 5000)
shapiro.test(slg)

# Detect outlier
out <- calculate_outliers(georgia$longitude)

# Print number of extreme outliers
out$num_extreme
```

**Variable 21: latitude**

The numerical variable latitude contains the latitude of each of the rental houses. There are no missing values and there are 5455 unique numerical values. The data is not normally distributed (confirmed by the Shapiro test) and ranges from 30.73 to 34.99. In addition, there are 82 extreme outliers.

```{r}
# Summary of the column
out_clt <- summary(georgia$latitude)
out_clt
# Any missing values
sum(is.na(georgia$latitude))
# First five elements
georgia$latitude[1:5]
# Number of unique values
length(unique(georgia$latitude))

hist(georgia$latitude, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$latitude), sd(georgia$latitude)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
slt <- sample(georgia$latitude, 5000)
shapiro.test(slt)

# Detect outlier
out <- calculate_outliers(georgia$latitude)

# Print number of extreme outliers
out$num_extreme
```

**Variable 22: hasBadGeocode**

This boolean variable indicates whether a row has bad geocode. Geocode allows we to take each observation's information and create a map of their locations. There are no missing values in the data, but there are only 0s thoughout the column, in other words, there are no observation with bad geocode, since we can determine the location of each house using the longitude and latitude columns in the dataset.

```{r}
# Summary of the column
summary(georgia$hasBadGeocode)
# Any missing values
sum(is.na(georgia$hasBadGeocode))
# First five elements
georgia$hasBadGeocode[1:5]
# Number of unique values
length(unique(georgia$hasBadGeocode))

hist(georgia$hasBadGeocode, breaks = 20, freq = F)
```

**Variable 23: description**

This categorical variable contains a textual description provided by the sellers of the rental houses. There are no missing values in the data, but not all descriptions are unique (unique values = 5429), there are some rows that share the same descriptions. This reminds us of the analysis we did with the variable 3: id. We found out that there are some observations with the same observations are equal in most of the variables, but there are some that do not follow that pattern. Maybe the sellers were so lazy that they copied and pasted one of the description they had on their hand on similar rental houses' posts.

```{r}
# Summary of the column
summary(georgia$description)
# Any missing values
sum(is.na(georgia$description))
# First five elements
georgia$description[1]
# Number of unique values
length(unique(georgia$description))

# Get duplicated descriptions
duplicated_descriptions <- georgia[duplicated(georgia$description) | duplicated(georgia$description, fromLast = TRUE), ]

# Some observations with the same description are equal in most of the variables
which(georgia$description == duplicated_descriptions$description[1])

# obs 19 vs obs 5718
georgia[c(19, 5718),]

# Not all observations with the same description are equal
which(georgia$description == duplicated_descriptions$description[6])

# obs 60 vs obs 174
georgia[c(60, 174),]
```

**Variable 24: currency**

This categorical variable contains the currency used in each of the observations. However, since we only have observations from Georgia state, the currency in each row is USA. And it has no missing values.

```{r}
# Summary of the column
summary(georgia$currency)
# Any missing values
sum(is.na(georgia$currency))
# First five elements
georgia$currency[1:5]
# Number of unique values
length(unique(georgia$currency))
```

**Variable 25: livingArea**

This numerical variable contains the living are of the rental houses in sqft. There are no missing values and it's not normally distributed. Although we said that it has no missing values, there is an observation where the livingArea is 1 (minimum value), this could be an error or missing value. There are in total 2601 unique values in the data. In addition, 9 extreme outliers are found, each of them are above 7000 sqft.

```{r}
# Summary of the column
out_cla <- summary(georgia$livingArea)
out_cla
# Observation with livingArea = 1
which(georgia$livingArea < 100) # 1282
# Any missing values
sum(is.na(georgia$livingArea))
# First five elements
georgia$livingArea[1:5]
# Number of unique values
length(unique(georgia$livingArea))

hist(georgia$livingArea, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$livingArea), sd(georgia$livingArea)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
sla <- sample(georgia$livingArea, 5000)
shapiro.test(sla)

# Detect outlier
out <- calculate_outliers(georgia$livingArea)

# Print number of extreme outliers
out$num_extreme
```

**Variable 26: livingAreaValue**

This numerical variable contains exactly the same values as the previous one, they are actually the same columns with a different column name.

```{r}
# Whether these two columns are equal
all(georgia$livingArea == georgia$livingAreaValue)
```
**Variable 27: bathrooms**

This numerical variable indicates the number of bathrooms each one of the rental houses has. There are no missing values (NAs) and it's not normally distributed. Thre are 11 unique values and 35 extreme outliers (> 6 bathrooms). Some of the observations have 0 bathrooms, these must be an error, so we will deal with them later with imputation.

```{r}
# Summary of the column
out_cb <- summary(georgia$bathrooms)
out_cb
# Any missing values
sum(is.na(georgia$bathrooms))
# First five elements
georgia$bathrooms[1:5]
# Number of unique values
length(unique(georgia$bathrooms))

hist(georgia$bathrooms, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$bathrooms), sd(georgia$bathrooms)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
sb <- sample(georgia$bathrooms, 5000)
shapiro.test(sb)

# Detect outlier
out <- calculate_outliers(georgia$bathrooms)

# Print number of extreme outliers
out$num_extreme
```

**Variable 28: bedrooms**

This numerical variable indicates the number of bedrooms each one of the rental houses has. There are no missing values (NAs) and it's not normally distributed. There are 12 unique values and 18 extreme outliers (> 7 bedrooms). Similar to the previous variable, some of the observations have 0 bedrooms, so we will also deal with them later with imputation.

```{r}
# Summary of the column
out_cbd <- summary(georgia$bedrooms)
out_cbd
# Any missing values
sum(is.na(georgia$bedrooms))
# First five elements
georgia$bedrooms[1:5]
# Number of unique values
length(unique(georgia$bedrooms))

hist(georgia$bedrooms, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$bedrooms), sd(georgia$bedrooms)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
sbd <- sample(georgia$bedrooms, 5000)
shapiro.test(sbd)

# Detect outlier
out <- calculate_outliers(georgia$bedrooms)

# Print number of extreme outliers
out$num_extreme
```

**Variable 29: buildingArea**

This numerical variable contains exactly the same values as the variables 24 and 25 (livingArea and livingAreaValue), they are actually the same columns with a different column name.

```{r}
# Whether these two columns are equal
all(georgia$livingAreaValue == georgia$buildingArea)
```

**Variable 30: parking**

The variable parking is a boolean variable that indicates whether the house offers parking. This variable has no missing values. The number of houses with parking (4711) exceeds the number of those which have not (1457).

```{r}
# Summary of the column
summary(georgia$parking)
# Any missing values
sum(is.na(georgia$parking))
# First five elements
georgia$parking[1:5]
# Number of unique values
length(unique(georgia$parking))

plot(factor(georgia$parking))
```

**Variable 31: garageSpaces**

The variable garageSpaces is a numerical variable that indicates the number of garage spaces in the house. This variable has no missing values and there are 8 unique values from 0 to 7. It's not normally distributed and there are no extreme outliers, but it has 5 mild outliers (> 5 garage spaces).

```{r}
# Summary of the column
out_cgs <- summary(georgia$garageSpaces)
out_cgs
# Any missing values
sum(is.na(georgia$garageSpaces))
# First five elements
georgia$garageSpaces[1:5]
# Number of unique values
length(unique(georgia$garageSpaces))

hist(georgia$garageSpaces, breaks = 20, freq = F)
curve(dnorm(x, mean(georgia$garageSpaces), sd(georgia$garageSpaces)), add = T)

# Shapiro test only accepts sample sizes between 3 and 5000
sgs <- sample(georgia$garageSpaces, 5000)
shapiro.test(sgs)

# Detect outlier
out <- calculate_outliers(georgia$garageSpaces)

# Print number of extreme outliers
out$num_mild
```

**Variable 32: hasGarage**

The variable hasGarage is a boolean variable that indicates whether the house has a garage. This variable has no missing values. The number of houses with a garage (3821) exceeds the number of those which have not (2347).

```{r}
# Summary of the column
summary(georgia$hasGarage)
# Any missing values
sum(is.na(georgia$hasGarage))
# First five elements
georgia$hasGarage[1:5]
# Number of unique values
length(unique(georgia$hasGarage))

plot(factor(georgia$hasGarage))

# Is there a house where the variable hasGarage is 0 and there are more than 0 garageSpaces?
which(georgia$garageSpaces > 0 & georgia$hasGarage == 0)
```

**Variable 33: levels**

The variable levels is a categorical variable that indicates the levels of the buildings. This variable has no missing values and it has 35 unique values, although the level "0" might indicate missing values in this variable. However, this variable is a bit messy, there are a lot of repeated labels, they may be written differently, but in fact, they have the same meaning. For instance, the label "3 Story" matches with "Tri-level".

```{r}
# Summary of the column
summary(georgia$levels)
# Any missing values
sum(is.na(georgia$levels))
# First five elements
georgia$levels[1:5]
# Number of unique values
length(unique(georgia$levels))

# Show all levels
unique(georgia$levels)
```

**Variable 34: pool**

The variable pool is a boolean variable that indicates whether the house has a pool This variable has no missing values. Only 438 observations out of 6168 have a pool.

```{r}
# Summary of the column
summary(georgia$pool)
# Any missing values
sum(is.na(georgia$pool))
# First five elements
georgia$pool[1:5]
# Number of unique values
length(unique(georgia$pool))

plot(factor(georgia$pool))

# Number of houses with pool
length(which(georgia$pool == 1))
```

**Variable 35: spa**

The variable spa is a boolean variable that indicates whether the house has spa This variable has no missing values. Only 644 observations out of 6168 have spa.

```{r}
# Summary of the column
summary(georgia$spa)
# Any missing values
sum(is.na(georgia$spa))
# First five elements
georgia$spa[1:5]
# Number of unique values
length(unique(georgia$spa))

plot(factor(georgia$spa))

# Number of houses with spa
length(which(georgia$spa == 1))
```

**Variable 36: isNewConstruction**

The variable isNewConstruction is a boolean variable that indicates whether a rental house is a new building. There are no missing values and only 388 observations out of 6168 are new.

```{r}
# Summary of the column
summary(georgia$isNewConstruction)
# Any missing values
sum(is.na(georgia$isNewConstruction))
# First five elements
georgia$isNewConstruction[1:5]
# Number of unique values
length(unique(georgia$isNewConstruction))

plot(factor(georgia$isNewConstruction))

# Number of new constructed houses
length(which(georgia$isNewConstruction == 1))
```

**Variable 37: hasPetsAllowed**

The variable hasPetsAllowed is a boolean variable that indicates whether it is allowed to have pets in the rental houses. There are no missing values and only 51 houses out of 6168 allow pets.

```{r}
# Summary of the column
summary(georgia$hasPetsAllowed)
# Any missing values
sum(is.na(georgia$hasPetsAllowed))
# First five elements
georgia$hasPetsAllowed[1:5]
# Number of unique values
length(unique(georgia$hasPetsAllowed))

plot(factor(georgia$hasPetsAllowed), )

# Number of pets allowing houses
length(which(georgia$hasPetsAllowed == 1))
```

**Variable 38: homeType**

The variable homeType is a categorical variable that indicates the type of the rental houses. This variable has 5 unique values and there are no missing values. The type "SINGLE_FAMILY" is predominant in the data, the rest of the labels have low presence throughout the data.

```{r}
# Summary of the column
summary(georgia$homeType)
# Any missing values
sum(is.na(georgia$homeType))
# First five elements
georgia$homeType[1:5]
# Number of unique values
length(unique(georgia$homeType))

plot(factor(georgia$homeType))
```

**Variable 39: county**

The variable county is a categorical variable that indicates the county in Georgia state where the building is located. This variable has 129 unique values and there are no missing values.

```{r}
# Summary of the column
summary(georgia$county)
# Any missing values
sum(is.na(georgia$county))
# First five elements
georgia$county[1:5]
# Number of unique values
length(unique(georgia$county))
```
## 2. Data preparation

In this section we will prepare the data in order to facilitate the later analysis. In the previous section we found different problems of each variable, so here we are going to either apply different cleaning functions to the columns or just remove them.

```{r}
# There are duplicated rows/obs in the dataset, we can use the column id to remove them
duplicated_rows <- duplicated(georgia$id, fromLast = TRUE) # Find duplicated rows from the bottom
georgia_clean <- georgia[!duplicated_rows, ] # Remove duplicated observations
```

```{r}
# We only want to keep observations from 2021
georgia_clean <- georgia_clean[georgia_clean$datePostedString == 2021,]
```

```{r}
# The column levels is messy and not consistent, since it has both numeric and categorical labels

# We are going to perform an explicit mapping for the 35 observed raw values into 14 categories + NA, which will be imputed after analyzing the data quality
mapping <- c(
  "One and One Half"                          = "1.5",
  "One"                                       = "1",
  "Two"                                       = "2",
  "Three Or More"                             = "3+",
  "Multi/Split"                               = "multi-split",
  "Multi/Split-Split Level"                   = "multi-split",
  "0"                                         = NA, # This value will be imputed
  "One-Two Story Foyer"                       = "multi-foyer",
  "Tri Level"                                 = "tri-level",
  "2.5 Story"                                 = "2.5",
  "Manufactured Home 1 Story"                 = "manufactured",
  "Two-Split Foyer"                           = "split-foyer",
  "One and One Half-Split Level"              = "multi-split",
  "Split Foyer"                               = "split-foyer",
  "One and One Half-Two"                      = "multi",
  "Two-Two Story Foyer"                       = "multi",
  "One and One Half-Multi/Split"              = "multi-split",
  "Three Or More-Two Story Foyer"             = "3+",
  "One-Two"                                   = "multi",
  "One-One and One Half"                      = "multi",
  "One-Manufactured Home 1 Story"             = "manufactured",
  "Multi/Split-Two"                           = "multi-split",
  "Two-Multi/Split"                           = "multi-split",
  "One-Other"                                 = "other",
  "Two-Three Or More"                         = "multi",
  "One-One and One Half-Two"                  = "multi",
  "Three Or More-Split Level-Tri-Level"       = "3+",
  "Two-Foyer - 2 Story"                       = "2",
  "Other-See Remarks"                         = "other-remarks",
  "Split Level"                               = "split",
  "3 Story"                                   = "3+",
  "Two-Split Level"                           = "split",
  "One-Mobile Home 1 Story"                   = "manufactured",
  "Tri Level-Split Level"                     = "tri-level",
  "Tri-Level"                                 = "tri-level"
)

# Apply mapping
georgia_clean$levels_mapped <- mapping[georgia_clean$levels]

```

```{r}
# Regarding the columns city/cityId and county/countyId, we noticed that they do not have the same number of unique variables. By the way, the column cityId has some missing values where the cityId equals 0.
length(unique(georgia$cityId)) == length(unique(georgia$city))

# It's because of that, in the following cell we will remove the columns cityId and countyId and retain city and county

```

```{r}
# The following columns just don't provide any useful information

# Columns to remove (we chose livingArea instead of pricePerSquareFoot)
cols_to_remove <- c(
  "X.1", "X", "id", "stateId", "country", "time", "cityId", "datePostedString",
  "state", "streetAddress", "hasBadGeocode", "description", 
  "currency", "livingAreaValue", "buildingArea", "hasPetsAllowed", 
  "is_bankOwned", "is_forAuction", "countyId", "pricePerSquareFoot", "levels"
)

# Remove them from the dataset
georgia_clean <- georgia_clean[, setdiff(names(georgia_clean), cols_to_remove)]

# Check remaining columns
names(georgia_clean)
```

```{r}
# Rental houses built in the future are not possible
georgia_clean[georgia_clean$yearBuilt > 2025,"yearBuilt"] <- NA
# Rental houses with 0 bedrooms or bathrooms are not acceptable
georgia_clean[georgia_clean$bedrooms == 0,"bedrooms"] <- NA
georgia_clean[georgia_clean$bathrooms == 0,"bathrooms"] <- NA
# In case hasGarage == 0 and garageSpaces > 0
georgia_clean[georgia_clean$hasGarage == 0 & georgia_clean$garageSpaces > 0,"hasGarage"] <- NA
georgia_clean[georgia_clean$hasGarage == 0 & georgia_clean$garageSpaces > 0,"garageSpaces"] <- NA
# In livingArea there is an observation with livingArea = 1
georgia_clean[georgia_clean$livingArea < 100,"livingArea"] <- NA

# These are preliminary extreme outliers we found, later we will assign NAs to each of the outliers found in these numerical variables using Boxplot

# As discussed in the exploratory data analysis, these missing values are likely the result of later updates to the rental houses. This could explain the presence of duplicated rows, or they might simply come from errors introduced during data collection or upload.
```

```{r}
# Removing trailing blanks and converting every category to lower case
georgia_clean <- georgia_clean %>%
  mutate(across(where(~ is.character(.) | is.factor(.)),
                ~ tolower(trimws(as.character(.)))))
# Doing this can reduce the number of unique values in categorical variables. For example, in the variable city we had originally 383 factors, but in the filtered dataset we have now 371 factors.
length(unique(georgia$city)) # Original dataset
length(unique(georgia_clean$city)) # Filtered dataset

```


```{r}
summary(georgia_clean)
```

As we can see from the summary statistics, the data generally makes sense and follows the expected rules for the housing field. Prices range from 6,250 USD to 1.3 million USD, which is plausible given the variability of the Georgia housing market. Structural variables like livingArea, bedrooms, and bathrooms mostly fall within reasonable ranges, though the maximums (10 bathrooms, 14 bedrooms) suggest a few outliers. yearBuilt spans 1800 to 2022, reflecting a mix of older and newer houses. Geographic variables (latitude, longitude, zipcode) lie within Georgia’s bounds. Logical patterns are generally consistent, for example, homes marked with hasGarage = 1 usually have a positive number of garageSpaces, and only a small fraction of properties are labeled as new constructions. Overall, the data supports the working theory that property characteristics such as size and age influence price, while occasional anomalies are likely due to minor data entry or collection errors rather than systemic issues in the dataset.

## 3. Data quality reports

**Variables**

Up to this points, all variables in the dataset have been explored. In terms of missingness, some of the variables have exaggerated values or error values, those could be considered as missing values. If we rank the numeric variables in terms of number of outliers, the following list is obtained, starting with the most outliers: longitude (97 extreme outliers), latitude (82 extreme outliers), pricePerSquareFoot (56 extreme outliers), price (43 extreme outliers), bathrooms (35 extreme outliers), bedrooms (18 extreme outliers), yearBuilt (16 extreme outliers), livingArea (9 extreme outliers, we are ignoring livingAreaValue and buildingArea, since they have the same values), zipcode (331 mild outliers) and garageSpaces (5 mild outliers).
 
**Univariate Analisis**

Now we will study the univariate outliers of the aforementioned variables. Firstly, the number of univariate outliers per individual are counted and added in a new variable called ‘univ_outl_count’. Looking at the individuals with the most univariate outliers (3) it can be concluded that they are all costly and have unusually high number of bathrooms and bedrooms.

The correlation matrix shows a positive correlation between price, bathrooms, bedrooms, livingArea and garageSpaces. This makes sense, as larger houses typically command higher prices due to the increased living space and associated amenities. Interestingly, the number of outliers appears to be negatively correlated with latitude, suggesting that properties located at lower latitudes tend to have more outliers.

```{r}
# longitude
georgia_clean$univ_outl_count <- 0

# Calculate outliers
out <- calculate_outliers(georgia_clean$longitude)
# Update the column univ_outl_count
georgia_clean[out$extreme_indexes, "univ_outl_count"] = georgia_clean[out$extreme_indexes, "univ_outl_count"] + 1
# Add NAs
georgia_clean[out$extreme_indexes, "longitude"] <- NA
```

```{r}
# latitude

# Calculate outliers
out <- calculate_outliers(georgia_clean$latitude)
# Update the column univ_outl_count
georgia_clean[out$extreme_indexes, "univ_outl_count"] = georgia_clean[out$extreme_indexes, "univ_outl_count"] + 1
# Add NAs
georgia_clean[out$extreme_indexes, "latitude"] <- NA
```

```{r}
# price

# Calculate outliers
out <- calculate_outliers(georgia_clean$price)
# Update the column univ_outl_count
georgia_clean[out$extreme_indexes, "univ_outl_count"] = georgia_clean[out$extreme_indexes, "univ_outl_count"] + 1
# Add NAs
georgia_clean[out$extreme_indexes, "price"] <- NA
```

```{r}
# bathrooms

# Calculate outliers
out <- calculate_outliers(georgia_clean$bathrooms)
# Update the column univ_outl_count
georgia_clean[out$extreme_indexes, "univ_outl_count"] = georgia_clean[out$extreme_indexes, "univ_outl_count"] + 1
# Add NAs
georgia_clean[out$extreme_indexes, "bathrooms"] <- NA
```

```{r}
# bedrooms

# Calculate outliers
out <- calculate_outliers(georgia_clean$bedrooms)
# Update the column univ_outl_count
georgia_clean[out$extreme_indexes, "univ_outl_count"] = georgia_clean[out$extreme_indexes, "univ_outl_count"] + 1
# Add NAs
georgia_clean[out$extreme_indexes, "bedrooms"] <- NA
```

```{r}
# yearBuilt

# Calculate outliers
out <- calculate_outliers(georgia_clean$yearBuilt)
# Update the column univ_outl_count
georgia_clean[out$extreme_indexes, "univ_outl_count"] = georgia_clean[out$extreme_indexes, "univ_outl_count"] + 1
# Add NAs
georgia_clean[out$extreme_indexes, "yearBuilt"] <- NA
```

```{r}
# livingArea

# Calculate outliers
out <- calculate_outliers(georgia_clean$livingArea)
# Update the column univ_outl_count
georgia_clean[out$extreme_indexes, "univ_outl_count"] = georgia_clean[out$extreme_indexes, "univ_outl_count"] + 1
# Add NAs
georgia_clean[out$extreme_indexes, "livingArea"] <- NA
```

```{r}
# zipcode

# Calculate outliers
out <- calculate_outliers(georgia_clean$zipcode)
# Update the column univ_outl_count
georgia_clean[out$mild_indexes, "univ_outl_count"] = georgia_clean[out$mild_indexes, "univ_outl_count"] + 1
# Add NAs (here we use mild outliers, since we don't have extreme outliers)
georgia_clean[out$mild_indexes, "zipcode"] <- NA
```

```{r}
# garageSpaces

# Calculate outliers
out <- calculate_outliers(georgia_clean$garageSpaces)
# Update the column univ_outl_count
georgia_clean[out$mild_indexes, "univ_outl_count"] = georgia_clean[out$mild_indexes, "univ_outl_count"] + 1
# Add NAs (here we use mild outliers, since we don't have extreme outliers)
georgia_clean[out$mild_indexes, "garageSpaces"] <- NA
```

```{r}
# There are observations with 3 outliers in those columns
max(georgia_clean$univ_outl_count)
# Print those individuals
georgia_clean[which(georgia_clean$univ_outl_count == 3),]
```

```{r}
# We are going to a create a correlation matrix of those columns
georgia_interest = georgia_clean[,c("longitude", "latitude", "price", "bathrooms", "bedrooms", "yearBuilt", "livingArea", "zipcode", "garageSpaces", "univ_outl_count")]
# Use pairwise.complete.obs to ignore NAs in each pair of variables
cor_outl = cor(georgia_interest, use = "pairwise.complete.obs")
par(mfrow=c(1,1))
corrplot(cor_outl, method = 'number', number.cex = 0.5)
```

**Data Imputation**

Here we will use imputePCA function to impute numerical data and imputeMCA for categorical variables.

```{r}
# We will use imputePCA to impute numerical variables
res.misMDA <- imputePCA(georgia_clean[, c(2,4:16)]) # Choosing numerical variables
# Get the completed dataset
georgia_clean[, c(2,4:16)] <- res.misMDA$completeObs
```

```{r}
# We will use imputeMCA to impute categorical variables
res.misMDA <- imputeMCA(georgia_clean[,c(1,3,17:19)]) # Choosing categorical variables
# Get the completed dataset
georgia_clean[, c(1,3,17:19)] <- res.misMDA$completeObs
```

```{r}
summary(georgia_clean) # The distribution of the imputed dataset seems to align the previous one
```

**Multivariate Analisis**

Moutlier is applied on the numerical variables to find multivariate outliers. With the garageSpaces variable included, however, the method returns a singular matrix. Therefore this variable is excluded from the calculation. A very mild threshold of 0.025 % is chosen as signficance level because is already returns a significant amount of outliers. This makes up around 7% of the total amount of instances. It is chosen to delete these outliers from the data set for the rest of the project. 

```{r}
# Use Moutlier that applies Mahalanobis distances to detect multivariate outliers
res.out = Moutlier(georgia_clean[,c("longitude", "latitude", "price", "bathrooms", "bedrooms", "yearBuilt", "livingArea", "zipcode")], quantile = 0.975, col="green") # Condidence level of 97.5%
```

```{r}
length(which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff))
 )/nrow(georgia_clean)
```

```{r}
# Plot all observations
par(mfrow=c(1,1))
plot(res.out$md, res.out$rd, xlab = "Mahalanobis Distance", ylab = "Robust Distance") 
abline(h=res.out$cutoff, col="red") 
abline(v=res.out$cutoff, col="red") 

```

```{r}
# Summary of only multivariate outliers
summary(georgia_clean[which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff)),])
```

```{r}
# Summary of the original dataset
summary(georgia_clean)
```

```{r}
# Remove those observations from the dataset
georgia_clean = georgia_clean[-which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff)),] 
```

**Profiling**

## Determine if the target variable (price) has an acceptably normal distribution. Address test to discard serial correlation. 

Now, we'd like to determine if the response variable (price) has an acceptably normal distribution. In addition, we used the acf() function to test for autocorrelation. The results indicate that the variable is not normally distributed and exhibits significant autocorrelation. The first few lags show high and positive autocorrelation, then it decreases gradually, indicating that values of price are correlated with their past values (the data are not independent). Therefore, the dataset is randomized to remove serial correlation before further analysis.

```{r}
# Plots the autocorrelation function to detect serial correlation in the data.
acf(georgia_clean$price)
# Serial correlation means that observations in our data are related across time, rather than being completely random or independent.
```

```{r}
# We can choose at most 5000 samples for shapiro test
ll <- sample(1:nrow(georgia_clean),nrow(georgia_clean), size = 5000) # Shuffling indexes
georgia_clean <- georgia_clean[ll,] # Shuffling data
acf(georgia_clean$price) 
```

```{r}
# We can choose at most 5000 samples for shapiro test
shapiro.test(georgia_clean$price[1:5000]) # Use the first 5000 obs

# H0: The price variable is normally distributes
# H1: The price variable is NOT normally distributes

# Since the p-value < 0.05, we reject H0.

# The variable georgia$price does not follow a normal distribution, it significantly deviates from normality.
```

```{r}
# This checks whether a sample comes from a specific theoretical distribution, in this case, a normal distribution with the same mean and standard deviation as our data.
ks.test(georgia_clean$price, 'pnorm', mean(georgia_clean$price), sd(georgia_clean$price))

# H0: georgia$price follows a normal distribution with the given mean and standard deviation
# H1: georgia$price does not follow that normal distribution.

# Because the p-value < 0.05, we reject H0.

# The K-S test confirms that the distribution of georgia$price significantly deviates from normality, meaning the data is not normally distributed.
```

```{r}
# Plot a histogram of price with a density curve
ggplot(data = georgia_clean, aes(x = price, y = after_stat(density))) + 
  geom_histogram(breaks = seq(0, max(georgia_clean$price), by = 10000),
                 col = "lightblue",
                 fill = "steelblue") +
  geom_density(lwd = 1, col = "red") +
  labs(title = "Histogram of Price with Density Curve",
       x = "Price",
       y = "Density")
```

## Indicate by exploration of the data which are apparently the variables most associated with the target variable (use only the indicated variables). 

To do this, the condes function of the FactoMiner package is used, which for the 
numeric target variable 'price' calculates the correlation of each of the quantitative variables and the coefficient of determination (R^2) for the qualitative variables, together with a p-value for significance.

For the quantitative variables, it is clear that both livingArea and bathrooms are highly significant and positively correlated with price (r > 0.50, p = 0). This is logical, as larger properties with more bathrooms tend to cost more. Although, theoretically, bedrooms might be expected to have a stronger correlation with price, bathrooms appear more decisive, possibly because properties in Georgia do not always need many bedrooms. Longitude and zipcode are negatively correlated with price (r < -0.10, p ~ 0), which is also expected, reflecting that certain geographic areas tend to have lower property values.

For the qualitative variables, it is clear that city explains the most variance in the price variable (R^2 = 0.38, p ~ 0), followed by county (R^2 = 0.25) and levels_mapped (R^2 = 0.19), all highly significant. This is expected, as geographic location and property layout strongly influence housing prices. Other categorical variables, such as homeType, have a much smaller effect (R^2 ~ 0.02), indicating only a minor association with price. Overall, the influence of qualitative variables decreases in the order: city, county, levels_mapped, homeType, with some variables contributing very little to explaining price variation. This aligns with expectations, as variables like location tend to dominate price determination, while others such as property type have comparatively limited impact.

```{r}
# Displays the summary of quantitative variables most related to the 2th column (price), showing how each numeric variable contributes or associates with it.
res.con = condes(georgia_clean,2) # The column corresponding to price

# Quantitative variables
res.con$quanti
# The p.value here assesses statistical significance of the correlation between each variable and price

# Qualitative variables
res.con$quali
# The coefficient of determination measures the proportion of variance in price explained by each categorical variable
```

## Define a polytomic factor f.yearBuilt for the building year of a house according to its quartiles and argue if the average price depends on the age of the building. Statistically justify the answer.






























