---
title: "Lab Assignment 1"
author: "Zheshuo and Geming"
date: "2025-10-05"
output: html_document
---

# ASSIGNMENT 1: GEORGIA HOUSE PRICE

## Before Starting

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Clear the plots
rm(list=ls()) # Clear the environment
```

We start by loading essential libraries, importing the data, and defining functions to simplify repetitive operations.

```{r}
# Installing dependencies
install.packages("lubridate")
```

```{r include = FALSE}
# Loading libraries
library(moments)
library(car)
library(chemometrics)
library(mice)
library(missMDA)
library(FactoMineR)
library(corrplot)
library(VIM)
library(dplyr)
library(ggplot2)
library(AER)
library(MASS)
library(dplyr)
library(lubridate)
library(stringr)
library(readr)
library(tidyr)
library(tidyselect)
```

```{r}
# Importing the main data of the assignment
georgia <- read.csv("RealEstate_Georgia.csv")
```

```{r}
# Get the dimension of the dataset
dim(georgia) # 6168 obs + 39 variables
```

```{r}
# Show the name of columns
names(georgia)
```

```{r}
# Check the structure of the dataset
str(georgia)
```

```{r}
# Use summary function to get a fast understanding of the dataset
summary(georgia)
```

## Variable Analysis

```{r}

```

## Data Cleaning

```{r}
# First, let's check if there is any missing values in the datase
sum(is.na(georgia)) # There are no NAs in the dataset
```


```{r}
# Next, we should filter and remove all observations that were not posted in 2021 and some validation based on common sense like bathrooms and bedrooms should be higher than 0.
georgia_2021_only <- georgia %>%
  filter(year(datePostedString) == 2021, bathrooms > 0, bedrooms > 0, price > 0) %>%
  distinct() # Retain unique rows

# While there are obs where the number of bathrooms and bedrooms is 0, there are no obs where the price is lower o equal to 0: length(which(georgia$price > 0)) == 6168

# After applying this filter, the new number of rows is 6097

```

```{r}
# Interestingly, the column id does not have the same number of unique values as the number of obs.
nrow(georgia_2021_only) == length(unique(georgia_2021_only$id)) # 6097 vs 5448

# On the other hand, the columns X.1 and X have the exact number of unique values as rows
length(unique(georgia_2021_only$X.1)) # 6097
length(unique(georgia_2021_only$X)) # 6098

# Since the columns X.1 and X do not provide any relevant information, we are just going to concatenate them to the tail of the column id, so it will have a unique value for every obs. Although the id itself is neither useful, we can still use it to identify the observations.
georgia_2021_only$id_unique <- paste0(georgia_2021_only$id, "_", 
                                      georgia_2021_only$X.1, "_", 
                                      georgia_2021_only$X)

# Move id_unique to the front and drop the old columns
georgia_2021_only <-
  georgia_2021_only[, c(ncol(georgia_2021_only), 1:ncol(georgia_2021_only)-1)]
georgia_2021_only$X.1 <- NULL
georgia_2021_only$X <- NULL
georgia_2021_only$id <- NULL

```

```{r}
# Let's check if there are columns that have only one value across the dataset
sapply(georgia_2021_only,n_distinct)

# Note that stateId, country, state, hasBadGeoCode and currency only have one factor throughout the dataset (16, USA, GA, 0, USD). These columns do not provide anything to the posterior analysis, so they should be eliminated. The following line removes all constant columns.
georgia_value_rem <- georgia_2021_only[,
              sapply(georgia_2021_only, function(x) length(unique(x)) > 1)]

```

```{r}
# We found that the columns is_bankOwned and is_forAuction only have one positive case for each of them in the filtered dataset. We should also remove these columns, since 99% of the rows have 0 in these two columns.
sum(georgia_value_rem$is_forAuction == 1)
#georgia_value_rem[which(georgia_value_rem$is_bankOwned == 1),]
sum(georgia_value_rem$is_bankOwned == 1)
#georgia_value_rem[which(georgia_value_rem$is_forAuction == 1),]

# Remove columns
georgia_value_rem$is_bankOwned <- NULL
georgia_value_rem$is_forAuction <- NULL
```

```{r}
# In the city column there are some factors registered in uppercase, we can also remove white spaces that might appear at the beginning and the end of each city.
unique(factor(georgia_value_rem$city))[293] # JOHNS CREEK

# The following line corrects that structure error
georgia_value_rem <- georgia_value_rem %>%
  mutate(
    city = city %>% str_trim() %>% str_to_title(),
    # Remove spaces and capitalize the first letter.
)

# Now the number of unique factors reduced from 380 to 370

```

```{r}
# The column levels is messy and not consistent, since it has both numeric and categorical labels
unique(factor(georgia_value_rem$levels))

# We are going to perform an explicit mapping for the 35 observed raw values
mapping <- c(
  "One and One Half"                          = "1.5",
  "One"                                       = "1",
  "Two"                                       = "2",
  "Three Or More"                             = "3+",
  "Multi/Split"                               = "multi",
  "Multi/Split-Split Level"                   = "multi",
  "0"                                         = NA,
  "One-Two Story Foyer"                       = "multi",
  "Tri Level"                                 = "split",
  "2.5 Story"                                 = "2.5",
  "Manufactured Home 1 Story"                 = "manufactured",
  "Two-Split Foyer"                           = "split",
  "One and One Half-Split Level"              = "multi",
  "Split Foyer"                               = "split",
  "One and One Half-Two"                      = "multi",
  "Two-Two Story Foyer"                       = "multi",
  "One and One Half-Multi/Split"              = "multi",
  "Three Or More-Two Story Foyer"             = "3+",
  "One-Two"                                   = "multi",
  "One-One and One Half"                      = "multi",
  "One-Manufactured Home 1 Story"             = "manufactured",
  "Multi/Split-Two"                           = "multi",
  "Two-Multi/Split"                           = "multi",
  "One-Other"                                 = "other",
  "Two-Three Or More"                         = "multi",
  "One-One and One Half-Two"                  = "multi",
  "Three Or More-Split Level-Tri-Level"       = "3+",
  "Two-Foyer - 2 Story"                       = "2",
  "Other-See Remarks"                         = "other",
  "Split Level"                               = "split",
  "3 Story"                                   = "3+",
  "Two-Split Level"                           = "split",
  "One-Mobile Home 1 Story"                   = "manufactured",
  "Tri Level-Split Level"                     = "split",
  "Tri-Level"                                 = "split"
)

# Apply mapping
georgia_value_rem <- georgia_value_rem %>%
  mutate(
    levels = mapping[as.character(levels)],
  )%>%
  filter(!is.na(levels)) # Rental houses with 0 stories are not possible, they need removing

```


```{r}
# which(georgia_2021_only$hasGarage == 1 & georgia_2021_only$garageSpaces == 0) -> is that even possible?
```

```{r}
# There are some columns that do not provide any useful information at all, like description, streetAddress, ... Can we eliminate them?
```


\newpage

Explanatory Data Analysis

In this section, we perform a crucial step in any data science project, especially when preparing data for modeling. A comprehensive descriptive analysis is carried out for each variable, emphasizing their most relevant characteristics. We proceed with a column-by-column examination of the dataset, followed by the generation of a data quality report. Subsequently, we prepare the data for the modeling phase by handling missing values through imputation techniques, removing non-informative variables, and creating new derived features where appropriate.

It is important to note that the explanatory data analysis is conducted exclusively on the training dataset. However, the creation and removal of variables derived from this process also affect the test dataset to ensure consistency across both sets.


Univariate Descriptive Analysis

In this initial phase, we analyze each variable in the dataset, emphasizing their key characteristics. Numeric variables that represent categorical or qualitative concepts are converted into factors, and new features may be created based on existing numerical variables to enhance model performance.

Finally, a comprehensive data quality report is presented, assessing the overall integrity of the dataset and discussing potential implications for the modeling process.




